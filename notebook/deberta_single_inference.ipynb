{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Reference: https://www.kaggle.com/code/kojimar/fb3-single-pytorch-model-inference/notebook","metadata":{"papermill":{"duration":0.003926,"end_time":"2022-11-03T07:32:42.83224","exception":false,"start_time":"2022-11-03T07:32:42.828314","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport time\nimport math\nimport random\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import mean_squared_error\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom transformers import DataCollatorWithPadding\n%env TOKENIZERS_PARALLELISM=false\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":8.398958,"end_time":"2022-11-03T07:32:51.235317","exception":false,"start_time":"2022-11-03T07:32:42.836359","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:17.921072Z","iopub.execute_input":"2022-12-12T06:16:17.921531Z","iopub.status.idle":"2022-12-12T06:16:21.029763Z","shell.execute_reply.started":"2022-12-12T06:16:17.921441Z","shell.execute_reply":"2022-12-12T06:16:21.028031Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"tokenizers.__version__: 0.12.1\ntransformers.__version__: 4.20.1\nenv: TOKENIZERS_PARALLELISM=false\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls ../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base  ","metadata":{"execution":{"iopub.status.busy":"2022-12-12T06:16:21.031656Z","iopub.execute_input":"2022-12-12T06:16:21.032576Z","iopub.status.idle":"2022-12-12T06:16:22.111315Z","shell.execute_reply.started":"2022-12-12T06:16:21.032534Z","shell.execute_reply":"2022-12-12T06:16:22.109684Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"config\nmicrosoft-deberta-v3-base_fold0_best.pth\nmicrosoft-deberta-v3-base_fold1_best.pth\nmicrosoft-deberta-v3-base_fold2_best.pth\nmicrosoft-deberta-v3-base_fold3_best.pth\nmicrosoft-deberta-v3-base_fold4_best.pth\nmodel\noof_df.pkl\ntokenizer\ntrain.log\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# CFG","metadata":{"papermill":{"duration":0.004246,"end_time":"2022-11-03T07:32:51.244185","exception":false,"start_time":"2022-11-03T07:32:51.239939","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CFG:\n    num_workers=1\n    path=\"../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/\"\n    config_path='../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/config/config.json'\n\n    model=\"microsoft/deberta-v3-base\"\n\n    tokenizer = AutoTokenizer.from_pretrained('../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/tokenizer')\n\n    batch_size = 16\n    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n    seed=42\n    n_fold=5\n    pooling = 'mean'\n","metadata":{"papermill":{"duration":0.428725,"end_time":"2022-11-03T07:32:51.677383","exception":false,"start_time":"2022-11-03T07:32:51.248658","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.113323Z","iopub.execute_input":"2022-12-12T06:16:22.116056Z","iopub.status.idle":"2022-12-12T06:16:22.410205Z","shell.execute_reply.started":"2022-12-12T06:16:22.116011Z","shell.execute_reply":"2022-12-12T06:16:22.409186Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Helper function","metadata":{"papermill":{"duration":0.004453,"end_time":"2022-11-03T07:32:51.687064","exception":false,"start_time":"2022-11-03T07:32:51.682611","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def MCRMSE(y_trues, y_preds):\n    scores = []\n    idxes = y_trues.shape[1]\n    for i in range(idxes):\n        y_true = y_trues[:,i]\n        y_pred = y_preds[:,i]\n        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n        scores.append(score)\n    mcrmse_score = np.mean(scores)\n    return mcrmse_score, scores\n\n\ndef get_score(y_trues, y_preds):\n    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n    return mcrmse_score, scores\n\n\ndef get_logger(filename='inference'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"papermill":{"duration":0.022425,"end_time":"2022-11-03T07:32:51.714607","exception":false,"start_time":"2022-11-03T07:32:51.692182","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.412670Z","iopub.execute_input":"2022-12-12T06:16:22.412993Z","iopub.status.idle":"2022-12-12T06:16:22.427891Z","shell.execute_reply.started":"2022-12-12T06:16:22.412964Z","shell.execute_reply":"2022-12-12T06:16:22.426943Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{"papermill":{"duration":0.004552,"end_time":"2022-11-03T07:32:51.724461","exception":false,"start_time":"2022-11-03T07:32:51.719909","status":"completed"},"tags":[]}},{"cell_type":"code","source":"oof_df = pd.read_pickle(CFG.path + 'oof_df.pkl')\nlabels = oof_df[CFG.target_cols].values\npreds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\nscore, scores = get_score(labels, preds)\nLOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')","metadata":{"papermill":{"duration":0.109108,"end_time":"2022-11-03T07:32:51.838358","exception":false,"start_time":"2022-11-03T07:32:51.72925","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.429614Z","iopub.execute_input":"2022-12-12T06:16:22.429995Z","iopub.status.idle":"2022-12-12T06:16:22.452145Z","shell.execute_reply.started":"2022-12-12T06:16:22.429958Z","shell.execute_reply":"2022-12-12T06:16:22.451083Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Score: 0.4547  Scores: [0.48641556475217557, 0.44828431121959056, 0.4142058965154835, 0.456364823623438, 0.47309781232197934, 0.4497085298858464]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Read test data","metadata":{"papermill":{"duration":0.004393,"end_time":"2022-11-03T07:32:51.847541","exception":false,"start_time":"2022-11-03T07:32:51.843148","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\nsubmission = pd.read_csv('../input/feedback-prize-english-language-learning/sample_submission.csv')","metadata":{"papermill":{"duration":0.026971,"end_time":"2022-11-03T07:32:51.880509","exception":false,"start_time":"2022-11-03T07:32:51.853538","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.453864Z","iopub.execute_input":"2022-12-12T06:16:22.454265Z","iopub.status.idle":"2022-12-12T06:16:22.466323Z","shell.execute_reply.started":"2022-12-12T06:16:22.454225Z","shell.execute_reply":"2022-12-12T06:16:22.465334Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# sort by length to speed up inference\ntest['tokenize_length'] = [len(CFG.tokenizer(text)['input_ids']) for text in test['full_text'].values]\ntest = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)","metadata":{"papermill":{"duration":0.031006,"end_time":"2022-11-03T07:32:51.916494","exception":false,"start_time":"2022-11-03T07:32:51.885488","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.467937Z","iopub.execute_input":"2022-12-12T06:16:22.468344Z","iopub.status.idle":"2022-12-12T06:16:22.486587Z","shell.execute_reply.started":"2022-12-12T06:16:22.468305Z","shell.execute_reply":"2022-12-12T06:16:22.485709Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.004351,"end_time":"2022-11-03T07:32:51.925914","exception":false,"start_time":"2022-11-03T07:32:51.921563","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        #max_length=CFG.max_len,\n        #pad_to_max_length=True,\n        #truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['full_text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"papermill":{"duration":0.016009,"end_time":"2022-11-03T07:32:51.946655","exception":false,"start_time":"2022-11-03T07:32:51.930646","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.488079Z","iopub.execute_input":"2022-12-12T06:16:22.488472Z","iopub.status.idle":"2022-12-12T06:16:22.496176Z","shell.execute_reply.started":"2022-12-12T06:16:22.488434Z","shell.execute_reply":"2022-12-12T06:16:22.494889Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min = 1e-9)\n        mean_embeddings = sum_embeddings/sum_mask\n        return mean_embeddings","metadata":{"papermill":{"duration":0.025697,"end_time":"2022-11-03T07:32:51.986444","exception":false,"start_time":"2022-11-03T07:32:51.960747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.497976Z","iopub.execute_input":"2022-12-12T06:16:22.498345Z","iopub.status.idle":"2022-12-12T06:16:22.508432Z","shell.execute_reply.started":"2022-12-12T06:16:22.498308Z","shell.execute_reply":"2022-12-12T06:16:22.507263Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.004457,"end_time":"2022-11-03T07:32:51.995997","exception":false,"start_time":"2022-11-03T07:32:51.99154","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n    \n        self.config = AutoConfig.from_pretrained(config_path, output_hidden_states=True)\n        LOGGER.info(self.config)\n       \n        self.model = AutoModel.from_config(self.config)\n\n        self.pool = MeanPooling()\n    \n        self.fc = nn.Linear(self.config.hidden_size, 6)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(feature)\n        return output","metadata":{"papermill":{"duration":0.023241,"end_time":"2022-11-03T07:32:52.023919","exception":false,"start_time":"2022-11-03T07:32:52.000678","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.512576Z","iopub.execute_input":"2022-12-12T06:16:22.512969Z","iopub.status.idle":"2022-12-12T06:16:22.524488Z","shell.execute_reply.started":"2022-12-12T06:16:22.512943Z","shell.execute_reply":"2022-12-12T06:16:22.523398Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{"papermill":{"duration":0.004915,"end_time":"2022-11-03T07:32:52.034747","exception":false,"start_time":"2022-11-03T07:32:52.029832","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"papermill":{"duration":0.014696,"end_time":"2022-11-03T07:32:52.054593","exception":false,"start_time":"2022-11-03T07:32:52.039897","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.526415Z","iopub.execute_input":"2022-12-12T06:16:22.527233Z","iopub.status.idle":"2022-12-12T06:16:22.537037Z","shell.execute_reply.started":"2022-12-12T06:16:22.527194Z","shell.execute_reply":"2022-12-12T06:16:22.536003Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in range(CFG.n_fold):\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path + f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n                       #map_location='cuda:0')\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"_kg_hide-output":true,"papermill":{"duration":832.569512,"end_time":"2022-11-03T07:46:44.629193","exception":false,"start_time":"2022-11-03T07:32:52.059681","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:16:22.538647Z","iopub.execute_input":"2022-12-12T06:16:22.539091Z","iopub.status.idle":"2022-12-12T06:17:13.589851Z","shell.execute_reply.started":"2022-12-12T06:16:22.539047Z","shell.execute_reply":"2022-12-12T06:17:13.588090Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"DebertaV2Config {\n  \"_name_or_path\": \"../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/config/config.json\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"903813027eb24eb196bbf1113d756f9d"}},"metadata":{}},{"name":"stderr","text":"DebertaV2Config {\n  \"_name_or_path\": \"../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/config/config.json\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a974c3bfe9c488685efc0810ae1e6c8"}},"metadata":{}},{"name":"stderr","text":"DebertaV2Config {\n  \"_name_or_path\": \"../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/config/config.json\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b727b7f3094347bfb9e96a5186b94737"}},"metadata":{}},{"name":"stderr","text":"DebertaV2Config {\n  \"_name_or_path\": \"../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/config/config.json\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97777f6f60be4cbc890de313370887e9"}},"metadata":{}},{"name":"stderr","text":"DebertaV2Config {\n  \"_name_or_path\": \"../input/fb3-single-pytorch-model-train/20221210-012010-deberta-v3-base/config/config.json\",\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-07,\n  \"max_position_embeddings\": 512,\n  \"max_relative_positions\": -1,\n  \"model_type\": \"deberta-v2\",\n  \"norm_rel_ebd\": \"layer_norm\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"pooler_dropout\": 0,\n  \"pooler_hidden_act\": \"gelu\",\n  \"pooler_hidden_size\": 768,\n  \"pos_att_type\": [\n    \"p2c\",\n    \"c2p\"\n  ],\n  \"position_biased_input\": false,\n  \"position_buckets\": 256,\n  \"relative_attention\": true,\n  \"share_att_key\": true,\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 0,\n  \"vocab_size\": 128100\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21118ef789f74d9185fe5270d372b3dd"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.008165,"end_time":"2022-11-03T07:46:44.645987","exception":false,"start_time":"2022-11-03T07:46:44.637822","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test[CFG.target_cols] = predictions.clip(1, 5)\nsubmission = submission.drop(columns=CFG.target_cols).merge(test[['text_id'] + CFG.target_cols], on='text_id', how='left')\ndisplay(submission.head())\nsubmission[['text_id'] + CFG.target_cols].to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.063367,"end_time":"2022-11-03T07:46:44.717085","exception":false,"start_time":"2022-11-03T07:46:44.653718","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-12T06:17:13.592516Z","iopub.execute_input":"2022-12-12T06:17:13.593234Z","iopub.status.idle":"2022-12-12T06:17:13.641039Z","shell.execute_reply.started":"2022-12-12T06:17:13.593193Z","shell.execute_reply":"2022-12-12T06:17:13.639938Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.954794  2.830154    3.183609     3.023073  2.772290   \n1  000BAD50D026  2.687237  2.472593    2.718755     2.396610  2.199555   \n2  00367BB2546B  3.524361  3.372531    3.598719     3.560580  3.448080   \n\n   conventions  \n0     2.722584  \n1     2.639388  \n2     3.309982  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.954794</td>\n      <td>2.830154</td>\n      <td>3.183609</td>\n      <td>3.023073</td>\n      <td>2.772290</td>\n      <td>2.722584</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.687237</td>\n      <td>2.472593</td>\n      <td>2.718755</td>\n      <td>2.396610</td>\n      <td>2.199555</td>\n      <td>2.639388</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.524361</td>\n      <td>3.372531</td>\n      <td>3.598719</td>\n      <td>3.560580</td>\n      <td>3.448080</td>\n      <td>3.309982</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}